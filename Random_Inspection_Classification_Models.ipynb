{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenyuxiang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time  \n",
    "from sklearn import metrics  \n",
    "import pickle as pickle  \n",
    "from sklearn.cross_validation import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_file_path):  \n",
    "    \n",
    "    training_df = pd.read_csv(data_file_path, header=0)\n",
    "    feature_cols = ['T0101','T0102','T0201','T0202','T0203','T0204','T0205','T0206','T0207','T0208','T0209','T0210','T0211','T0212','T0213',\n",
    "'T0301','T0302','T0303','T0304','T0305','T0306','T0307','T0308','T0309']\n",
    "    x = training_df[feature_cols]\n",
    "    y = training_df['RANDOM_INSPECTION']\n",
    "    x_train,x_test, y_train, y_test = train_test_split(x, y, random_state=1) \n",
    "    \n",
    "    return training_df, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"C:/Users/chenyuxiang/Desktop/Random_Inspection_all_data.csv\"  \n",
    "\n",
    "all_data_df, train_x, train_y, test_x, test_y = read_data(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading training and testing data...\n",
      "******************* NB ********************\n",
      "training took 0.056000s!\n",
      "accuracy: 57.08%\n",
      "******************* KNN ********************\n",
      "training took 0.670000s!\n",
      "accuracy: 61.68%\n",
      "******************* LR ********************\n",
      "training took 0.267000s!\n",
      "accuracy: 61.81%\n",
      "******************* RF ********************\n",
      "training took 0.143000s!\n",
      "accuracy: 63.34%\n",
      "******************* DT ********************\n",
      "training took 0.047000s!\n",
      "accuracy: 63.02%\n",
      "******************* SVM ********************\n",
      "training took 189.117000s!\n",
      "accuracy: 59.79%\n",
      "******************* SVMCV ********************\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenyuxiang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 38.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 10\n",
      "cache_size 200\n",
      "class_weight None\n",
      "coef0 0.0\n",
      "decision_function_shape ovr\n",
      "degree 3\n",
      "gamma 0.001\n",
      "kernel rbf\n",
      "max_iter -1\n",
      "probability True\n",
      "random_state None\n",
      "shrinking True\n",
      "tol 0.001\n",
      "verbose False\n",
      "training took 2572.504127s!\n",
      "accuracy: 59.89%\n",
      "******************* GBDT ********************\n",
      "training took 1.928193s!\n",
      "accuracy: 63.59%\n"
     ]
    }
   ],
   "source": [
    "import time  \n",
    "from sklearn import metrics  \n",
    "import pickle as pickle  \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split  #引用交叉验证  \n",
    "\n",
    "# 定义8种不同的分类学习模型、\n",
    "\n",
    "# Multinomial Naive Bayes Classifier  \n",
    "def naive_bayes_classifier(train_x, train_y):  \n",
    "    from sklearn.naive_bayes import MultinomialNB  \n",
    "    model = MultinomialNB(alpha=0.01)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "  \n",
    "  \n",
    "# KNN Classifier  \n",
    "def knn_classifier(train_x, train_y):  \n",
    "    from sklearn.neighbors import KNeighborsClassifier  \n",
    "    model = KNeighborsClassifier()  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "  \n",
    "  \n",
    "# Logistic Regression Classifier  \n",
    "def logistic_regression_classifier(train_x, train_y):  \n",
    "    from sklearn.linear_model import LogisticRegression  \n",
    "    model = LogisticRegression(penalty='l2')  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "  \n",
    "  \n",
    "# Random Forest Classifier  \n",
    "def random_forest_classifier(train_x, train_y):  \n",
    "    from sklearn.ensemble import RandomForestClassifier  \n",
    "    model = RandomForestClassifier(n_estimators=8)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "  \n",
    "  \n",
    "# Decision Tree Classifier  \n",
    "def decision_tree_classifier(train_x, train_y):  \n",
    "    from sklearn import tree  \n",
    "    model = tree.DecisionTreeClassifier()  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "  \n",
    "  \n",
    "# GBDT(Gradient Boosting Decision Tree) Classifier  \n",
    "def gradient_boosting_classifier(train_x, train_y):  \n",
    "    from sklearn.ensemble import GradientBoostingClassifier  \n",
    "    model = GradientBoostingClassifier(n_estimators=200)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "  \n",
    "  \n",
    "# SVM Classifier  \n",
    "def svm_classifier(train_x, train_y):  \n",
    "    from sklearn.svm import SVC  \n",
    "    model = SVC(kernel='rbf', probability=True)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "  \n",
    "# SVM Classifier using cross validation  \n",
    "def svm_cross_validation(train_x, train_y):  \n",
    "    from sklearn.grid_search import GridSearchCV  \n",
    "    from sklearn.svm import SVC  \n",
    "    model = SVC(kernel='rbf', probability=True)  \n",
    "    param_grid = {'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}  \n",
    "    grid_search = GridSearchCV(model, param_grid, n_jobs = 1, verbose=1)  \n",
    "    grid_search.fit(train_x, train_y)  \n",
    "    best_parameters = grid_search.best_estimator_.get_params()  \n",
    "    for para, val in list(best_parameters.items()):  \n",
    "        print(para, val)  \n",
    "    model = SVC(kernel='rbf', C=best_parameters['C'], gamma=best_parameters['gamma'], probability=True)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "  \n",
    " \n",
    "thresh = 0.5  \n",
    "\n",
    "model_save = {}  \n",
    "test_classifiers = ['NB', 'KNN', 'LR', 'RF', 'DT', 'SVM','SVMCV', 'GBDT']  \n",
    "#test_classifiers = ['NB', 'KNN', 'LR', 'RF', 'DT', 'SVM','SVMCV', 'GBDT']  \n",
    "classifiers = {'NB':naive_bayes_classifier,   \n",
    "                  'KNN':knn_classifier,  \n",
    "                   'LR':logistic_regression_classifier,  \n",
    "                   'RF':random_forest_classifier,  \n",
    "                   'DT':decision_tree_classifier,  \n",
    "                  'SVM':svm_classifier,  \n",
    "                'SVMCV':svm_cross_validation,  \n",
    "                 'GBDT':gradient_boosting_classifier  \n",
    "}  \n",
    "      \n",
    "print('reading training and testing data...')  \n",
    "all_data, train_x, train_y, test_x, test_y = read_data(data_file)  \n",
    "      \n",
    "for classifier in test_classifiers:  \n",
    "    print('******************* %s ********************' % classifier)  \n",
    "    start_time = time.time()  \n",
    "    model = classifiers[classifier](train_x, train_y)  \n",
    "    print('training took %fs!' % (time.time() - start_time))  \n",
    "    predict = model.predict(test_x)  \n",
    "    model_save[classifier] = model  \n",
    "    #precision = metrics.precision_score(test_y, predict)  \n",
    "    #recall = metrics.recall_score(test_y, predict)  \n",
    "    #print('precision: %.2f%%, recall: %.2f%%' % (100 * precision, 100 * recall))  \n",
    "    accuracy = metrics.accuracy_score(test_y, predict)  \n",
    "    print('accuracy: %.2f%%' % (100 * accuracy))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
